{"cells":[{"cell_type":"markdown","metadata":{"id":"RcThZ5VUgaPo"},"source":["# Iris Logistic Regression"]},{"cell_type":"markdown","metadata":{},"source":["The dataset consists of three classes of irises. The objective is to create a classifier that will predict whether an iris belongs to the ‘Iris-setosa' class or not.\n","\n","This means that we have two classes: ‘Iris-setosa' and not-‘Iris-setosa’ (which includes 'Iris-versicolour' and 'Iris-virginica').\n","\n","Identify your independent variable x.\n","\n","Encode your dependent variable y such that ‘Iris-setosa' is encoded as 0, and 'Iris-versicolour' and 'Iris-virginica' are both encoded as 1. (0 corresponds to the 'Iris-setosa' class, and 1 corresponds to the not-‘Iris-setosa' class.)\n","\n","\n","Split the data into a training and test set.\n","\n","\n","Use sklearn’s logistic regression function to fit a model and make predictions on the test set.\n","\n","\n","Use sklearn to generate a confusion matrix, which compares thecpredicted labels to the actual labels (gold labels).\n","\n","\n","Analyse the confusion matrix and provide a prediction, in a comment, on whether the model is likely to have higher precision, higher recall, or similar precision and recall.\n","\n","\n","Write your own code to calculate the accuracy, precision, and recall, and check whether your prediction was right."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"XWMypTRbgaPw","outputId":"00f48efe-278a-45e5-9273-2b0381f5ce41"},"outputs":[],"source":["# importing libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import preprocessing\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal length (cm)</th>\n","      <th>sepal width (cm)</th>\n","      <th>petal length (cm)</th>\n","      <th>petal width (cm)</th>\n","      <th>Species</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n","0                5.1               3.5                1.4               0.2   \n","1                4.9               3.0                1.4               0.2   \n","2                4.7               3.2                1.3               0.2   \n","3                4.6               3.1                1.5               0.2   \n","4                5.0               3.6                1.4               0.2   \n","\n","   Species  \n","0        0  \n","1        0  \n","2        0  \n","3        0  \n","4        0  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# importing the dataset\n","iris = load_iris()\n","data = pd.DataFrame(iris.data, columns=iris.feature_names)\n","data['Species'] = iris.target\n","data.head()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Columns of the dataset:\n","Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n","       'petal width (cm)', 'Species'],\n","      dtype='object')\n"]}],"source":["print(\"\\nColumns of the dataset:\")\n","print(data.columns)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Value counts of the target variable:\n","Species\n","0    50\n","1    50\n","2    50\n","Name: count, dtype: int64\n"]}],"source":["print(\"\\nValue counts of the target variable:\")\n","print(data[\"Species\"].value_counts())"]},{"cell_type":"markdown","metadata":{},"source":["Identify the independent variable x and encode the dependent variable y:"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"-yYXhO8LgaRV"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Encoded Target Variable Preview (Binary):\n","[0 0 0 0 0]\n"]}],"source":["# Independent variables (features)\n","X = data.iloc[:,[0,1,2,3]].values\n","# Dependent variable (target)\n","y = data.iloc[:,4].values\n","# Encode the target variable such that 'Iris-setosa' is 0 and others are 1\n","y_binary = np.where(data['Species'] == 0, 0, 1)\n","# Display the first few rows to check the 'Iris-setosa' encoding\n","print(\"\\nEncoded Target Variable Preview (Binary):\")\n","print(y_binary[:5])"]},{"cell_type":"markdown","metadata":{},"source":["Split the data into a training and test set"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Training and Test Set Shapes (X_train.shape, X_test.shape, y_train.shape, y_test.shape):\n","(112, 4) (38, 4) (112,) (38,)\n"]}],"source":["# Scale the features\n","X = preprocessing.scale(X)\n","X = preprocessing.scale(X) # scale the data so that it is easier to fit\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.25, random_state=0)\n","\n","# Display the shape of the training and test sets\n","print(\"\\nTraining and Test Set Shapes (X_train.shape, X_test.shape, y_train.shape, y_test.shape):\")\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["Fit a logistic regression model and make predictions on the test set"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"2vdkRridglTj"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Predictions on the Test Set (Binary):\n","[1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0\n"," 1]\n"]}],"source":["# Fit a model\n","log_reg = LogisticRegression()\n","log_reg.fit(X_train, y_train)\n","\n","# Make predictions on test data\n","y_pred = log_reg.predict(X_test)\n","\n","# Display the predictions\n","print(\"\\nPredictions on the Test Set (Binary):\")\n","print(y_pred)"]},{"cell_type":"markdown","metadata":{"id":"Zljk3RohgaSo"},"source":["### Measuring Model Performance\n"]},{"cell_type":"markdown","metadata":{"id":"9D2wCVXo2XvP"},"source":["Generates and displays the confusion matrix."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136},"id":"Ey1Ro-MYgaSq","outputId":"ebb769ef-dd33-44ba-c85b-c5bd6436ce67"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Confusion Matrix (Binary):\n","[[13  0]\n"," [ 0 25]]\n"]}],"source":["# Generate the confusion matrix\n","conf_mat = confusion_matrix(y_test, y_pred)\n","\n","# Display confusion matrix\n","print(\"\\nConfusion Matrix (Binary):\")\n","print(conf_mat)"]},{"cell_type":"markdown","metadata":{"id":"gxii7pl224vE"},"source":["Analyse the confusion matrix and calculate accuracy, precision, and recall"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Accuracy (Binary): 1.0\n","Precision (Binary): 1.0\n","Recall (Binary): 1.0\n"]}],"source":["# Calculate and display accuracy, precision, and recall using sklearn\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","\n","print(f\"\\nAccuracy (Binary): {accuracy}\")\n","print(f\"Precision (Binary): {precision}\")\n","print(f\"Recall (Binary): {recall}\")"]},{"cell_type":"markdown","metadata":{},"source":["Write your own code to calculate accuracy, precision, and recall"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Manual Accuracy: 1.0\n","Manual Precision: 1.0\n","Manual Recall: 1.0\n"]}],"source":["# Calculate accuracy, precision, and recall manually\n","tp = conf_mat[1, 1]  # True positives\n","tn = conf_mat[0, 0]  # True negatives\n","fp = conf_mat[0, 1]  # False positives\n","fn = conf_mat[1, 0]  # False negatives\n","\n","# Accuracy\n","accuracy_manual = (tp + tn) / (tp + tn + fp + fn)\n","# Precision\n","precision_manual = tp / (tp + fp)\n","# Recall\n","recall_manual = tp / (tp + fn)\n","\n","print(f\"Manual Accuracy: {accuracy_manual}\")\n","print(f\"Manual Precision: {precision_manual}\")\n","print(f\"Manual Recall: {recall_manual}\")"]},{"cell_type":"markdown","metadata":{},"source":["Compare manual results vs sklearn results"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Do manual calculations match sklearn results?\n"]}],"source":["# Check if the manual calculations match the sklearn results\n","print(\"\\nDo manual calculations match sklearn results?\")"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy match: True\n"]}],"source":["# Check if the manual calculations match the sklearn results\n","print(f\"Accuracy match: {accuracy == accuracy_manual}\")"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Precision match: True\n"]}],"source":["# Check if the manual calculations match the sklearn results\n","print(f\"Precision match: {precision == precision_manual}\")"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Precision match: True\n"]}],"source":["# Check if the manual calculations match the sklearn results\n","print(f\"Precision match: {precision == precision_manual}\")"]},{"cell_type":"markdown","metadata":{},"source":["(Optional) Repeat this task but change it so that we only have all three categories ‘Iris-setosa', 'Iris-versicolour', and 'Iris-virginica' corresponding to the numeric values 0, 1, and 2 respectively; this will now be a three-class problem. Observe how this changes the confusion matrix."]},{"cell_type":"markdown","metadata":{},"source":["Encode y such that 'Iris-setosa' is 0, 'Iris-versicolor' is 1, and 'Iris-virginica' is 2."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Encoded Target Variable Preview (All classes):\n","0    0\n","1    0\n","2    0\n","3    0\n","4    0\n","Name: Species, dtype: int32\n"]}],"source":["# Encode the target variable such that 'Iris-setosa' is 0, 'Iris-versicolor' is 1, and 'Iris-virginica' is 2\n","y_optional = data['Species']\n","# Display the first few rows to check the encoding\n","print(\"\\nEncoded Target Variable Preview (All classes):\")\n","print(y_optional.head())"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Training and Test Set Shapes (X_train_optional.shape, X_test_optional.shape, y_train_optional.shape, y_test_optional.shape):\n","(112, 4) (38, 4) (112,) (38,)\n"]}],"source":["# Split the data into training and test sets\n","X_train_optional, X_test_optional, y_train_optional, y_test_optional = train_test_split(X, \n","                y_optional, test_size=0.25, random_state=0)\n","\n","# Display the shape of the training and test sets\n","print(\"\\nTraining and Test Set Shapes (X_train_optional.shape, X_test_optional.shape, y_train_optional.shape, y_test_optional.shape):\")\n","print(X_train_optional.shape, X_test_optional.shape, y_train_optional.shape, y_test_optional.shape)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Predictions on the Test Set (All classes):\n","[2 1 0 2 0 2 0 2 1 1 1 2 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n"," 2]\n"]}],"source":["# Initialize the logistic regression model for multi-class classification using OvR\n","l_g_optional = LogisticRegression(multi_class='ovr')#\n","\n","# Fit the model for multi-class classification\n","l_g_optional.fit(X_train_optional, y_train_optional)\n","\n","# Make predictions on the test set\n","y_pred_optional = l_g_optional.predict(X_test_optional)\n","\n","# Display the predictions\n","print(\"\\nPredictions on the Test Set (All classes):\")\n","print(y_pred_optional)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Confusion Matrix for all classes problem:\n","[[13  0  0]\n"," [ 0 13  3]\n"," [ 0  1  8]]\n"]}],"source":["# Generate the confusion matrix\n","cm_optional = confusion_matrix(y_test_optional, y_pred_optional)\n","\n","# Display the confusion matrix\n","print(\"\\nConfusion Matrix for all classes problem:\")\n","print(cm_optional)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Accuracy (all-class): 0.8947368421052632\n","Precision (all-class): 0.8852813852813853\n","Recall (all-class): 0.9004629629629629\n"]}],"source":["# Calculate and display accuracy, precision, and recall for multi-class classification using sklearn\n","accuracy_optional = accuracy_score(y_test_optional, y_pred_optional)\n","precision_optional = precision_score(y_test_optional, y_pred_optional, average='macro')\n","recall_optional = recall_score(y_test_optional, y_pred_optional, average='macro')\n","\n","print(f\"\\nAccuracy (all-class): {accuracy_optional}\")\n","print(f\"Precision (all-class): {precision_optional}\")\n","print(f\"Recall (all-class): {recall_optional}\")"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["F1 Score (Multi-class): 0.888888888888889\n"]}],"source":["# Calculate the F1 score for multi-class classification\n","f1_optional = f1_score(y_test_optional, y_pred_optional, average='macro')\n","print(f\"F1 Score (Multi-class): {f1_optional}\")"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Hardest class: virginica\n"]}],"source":["# Calculate the F1 score for each class and determine the hardest class\n","f1_scores_per_class = f1_score(y_test_optional, y_pred_optional, average=None)\n","lowest_f1_score = min(f1_scores_per_class)\n","hardest_class_index = list(f1_scores_per_class).index(lowest_f1_score)\n","hardest_class = iris.target_names[hardest_class_index]\n","print(f\"Hardest class: {hardest_class}\")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Recall for 'virginica': 0.8888888888888888\n","Precision for 'virginica': 0.7272727272727273\n"]}],"source":["# Calculate precision and recall for 'virginica' class manually\n","class_index = list(iris.target_names).index('virginica')\n","recall_virginica = recall_score(y_test_optional == class_index, y_pred_optional == class_index)\n","precision_virginica = precision_score(y_test_optional == class_index, y_pred_optional == class_index)\n","print(f\"Recall for 'virginica': {recall_virginica}\")\n","print(f\"Precision for 'virginica': {precision_virginica}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
